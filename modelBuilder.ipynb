{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([0.09019608, 0.38431373, 0.17647059, 0.26757946, 0.76535234,\n",
      "       0.20844889]), array([0., 1.])), (array([0.1372549 , 0.17647059, 0.16078431, 0.32431124, 0.74807843,\n",
      "       0.18628906]), array([1., 0.])), (array([0.25490196, 0.28235294, 0.26666667, 0.31435999, 0.81633494,\n",
      "       0.18057292]), array([1., 0.])), (array([0.30980392, 0.2627451 , 0.23921569, 0.24941262, 0.75845291,\n",
      "       0.17911784]), array([1., 0.])), (array([0.30588235, 0.25098039, 0.25098039, 0.2832827 , 0.78475314,\n",
      "       0.17674316]), array([1., 0.])), (array([0.31764706, 0.34509804, 0.34509804, 0.30665787, 0.80667975,\n",
      "       0.18063639]), array([1., 0.])), (array([0.41960784, 0.45490196, 0.2745098 , 0.26152252, 0.71580386,\n",
      "       0.23274577]), array([0., 1.])), (array([0.11764706, 0.45882353, 0.28627451, 0.26596437, 0.73852512,\n",
      "       0.21783366]), array([0., 1.])), (array([0.20784314, 0.28627451, 0.31372549, 0.3482852 , 0.79757154,\n",
      "       0.20687012]), array([1., 0.])), (array([0.29019608, 0.23137255, 0.18823529, 0.27455813, 0.79593257,\n",
      "       0.1768929 ]), array([1., 0.])), (array([0.4       , 0.46666667, 0.45882353, 0.32201165, 0.75368026,\n",
      "       0.20090658]), array([1., 0.])), (array([0.03137255, 0.26666667, 0.09803922, 0.26503609, 0.76568914,\n",
      "       0.21554199]), array([0., 1.])), (array([0.10980392, 0.44705882, 0.20784314, 0.24620496, 0.71310567,\n",
      "       0.22509603]), array([0., 1.])), (array([0.02745098, 0.23529412, 0.08627451, 0.25619599, 0.73854791,\n",
      "       0.21882487]), array([0., 1.])), (array([0.11372549, 0.4       , 0.16862745, 0.26784086, 0.74937823,\n",
      "       0.16575846]), array([0., 1.])), (array([0.10980392, 0.1254902 , 0.11372549, 0.31880721, 0.80884659,\n",
      "       0.18467611]), array([1., 0.])), (array([0.26666667, 0.29411765, 0.2745098 , 0.32672833, 0.80047959,\n",
      "       0.17984212]), array([1., 0.])), (array([0.30196078, 0.42352941, 0.26666667, 0.28843198, 0.64245197,\n",
      "       0.24296061]), array([0., 1.])), (array([0.2745098 , 0.30588235, 0.29019608, 0.32144178, 0.80572448,\n",
      "       0.18308594]), array([1., 0.])), (array([0.16078431, 0.42745098, 0.20392157, 0.25735405, 0.78869321,\n",
      "       0.14534342]), array([0., 1.])), (array([0.36862745, 0.45490196, 0.29019608, 0.2672446 , 0.66326984,\n",
      "       0.2427002 ]), array([0., 1.])), (array([0.03529412, 0.27058824, 0.10196078, 0.26216372, 0.74466816,\n",
      "       0.20720052]), array([0., 1.])), (array([0.05882353, 0.30196078, 0.1254902 , 0.26662424, 0.76648288,\n",
      "       0.2002474 ]), array([0., 1.])), (array([0.25490196, 0.28235294, 0.2627451 , 0.30898844, 0.81013795,\n",
      "       0.18505534]), array([1., 0.])), (array([0.11372549, 0.39215686, 0.16470588, 0.25290853, 0.78513938,\n",
      "       0.16035807]), array([0., 1.])), (array([0.11372549, 0.41176471, 0.16470588, 0.25155682, 0.75953442,\n",
      "       0.16207357]), array([0., 1.])), (array([0.03137255, 0.29019608, 0.15294118, 0.26712888, 0.7351143 ,\n",
      "       0.21878743]), array([0., 1.])), (array([0.30588235, 0.25882353, 0.25098039, 0.28634382, 0.77435269,\n",
      "       0.18010254]), array([1., 0.])), (array([0.0745098 , 0.38039216, 0.1254902 , 0.26512488, 0.75409184,\n",
      "       0.15747559]), array([0., 1.])), (array([0.0627451 , 0.34509804, 0.10980392, 0.2503353 , 0.81494751,\n",
      "       0.20214518]), array([0., 1.])), (array([0.16078431, 0.20784314, 0.19607843, 0.33456372, 0.74593679,\n",
      "       0.1905599 ]), array([1., 0.])), (array([0.24313725, 0.29019608, 0.22745098, 0.29845434, 0.81445704,\n",
      "       0.18923665]), array([1., 0.])), (array([0.31764706, 0.38823529, 0.30980392, 0.3046549 , 0.8026199 ,\n",
      "       0.18548828]), array([1., 0.])), (array([0.31764706, 0.35686275, 0.34509804, 0.3204779 , 0.75817733,\n",
      "       0.19512207]), array([1., 0.])), (array([0.17254902, 0.42745098, 0.22352941, 0.26247311, 0.76067835,\n",
      "       0.16243652]), array([0., 1.])), (array([0.05098039, 0.38431373, 0.10588235, 0.25225661, 0.7877507 ,\n",
      "       0.16774577]), array([0., 1.])), (array([0.08627451, 0.12941176, 0.12941176, 0.33119076, 0.76480997,\n",
      "       0.20330078]), array([1., 0.])), (array([0.10588235, 0.25882353, 0.12941176, 0.24980787, 0.74117004,\n",
      "       0.21189453]), array([0., 1.])), (array([0.10588235, 0.25882353, 0.0745098 , 0.2450556 , 0.78650807,\n",
      "       0.20642253]), array([0., 1.])), (array([0.28627451, 0.2627451 , 0.23137255, 0.26603168, 0.74145247,\n",
      "       0.17690592]), array([1., 0.])), (array([0.38039216, 0.43921569, 0.29019608, 0.26791957, 0.66322748,\n",
      "       0.24168294]), array([0., 1.])), (array([0.32941176, 0.27843137, 0.25882353, 0.28086964, 0.79847226,\n",
      "       0.17523763]), array([1., 0.])), (array([0.38431373, 0.45882353, 0.47843137, 0.30573874, 0.67255929,\n",
      "       0.20651204]), array([1., 0.])), (array([0.14901961, 0.40784314, 0.21176471, 0.26131801, 0.80145396,\n",
      "       0.16436198]), array([0., 1.])), (array([0.25490196, 0.28627451, 0.2745098 , 0.31316994, 0.82009458,\n",
      "       0.18911296]), array([1., 0.])), (array([0.32156863, 0.38039216, 0.30196078, 0.31911395, 0.75615969,\n",
      "       0.18022298]), array([1., 0.])), (array([0.18431373, 0.22352941, 0.19215686, 0.32668646, 0.80463913,\n",
      "       0.17367188]), array([1., 0.])), (array([0.04705882, 0.2627451 , 0.08627451, 0.25009203, 0.81030404,\n",
      "       0.19624023]), array([0., 1.])), (array([0.30588235, 0.39607843, 0.19607843, 0.24171533, 0.78577072,\n",
      "       0.21366211]), array([0., 1.])), (array([0.17254902, 0.43921569, 0.25098039, 0.27585453, 0.71378174,\n",
      "       0.17914714]), array([0., 1.])), (array([0.0745098 , 0.24705882, 0.11764706, 0.25628567, 0.74302263,\n",
      "       0.22194173]), array([0., 1.])), (array([0.39215686, 0.43529412, 0.24313725, 0.25358935, 0.71196279,\n",
      "       0.23495931]), array([0., 1.])), (array([0.10980392, 0.42352941, 0.17254902, 0.23922048, 0.76952582,\n",
      "       0.18906738]), array([0., 1.])), (array([0.27058824, 0.25490196, 0.23921569, 0.28218182, 0.74504835,\n",
      "       0.18471354]), array([1., 0.])), (array([0.12156863, 0.12941176, 0.10980392, 0.30707283, 0.82485592,\n",
      "       0.17937663]), array([1., 0.])), (array([0.27058824, 0.30196078, 0.28627451, 0.30847522, 0.81511437,\n",
      "       0.18322428]), array([1., 0.])), (array([0.27843137, 0.32941176, 0.25882353, 0.31430111, 0.8132359 ,\n",
      "       0.17750488]), array([1., 0.])), (array([0.05490196, 0.28627451, 0.08627451, 0.24685656, 0.82772407,\n",
      "       0.19510254]), array([0., 1.])), (array([0.19607843, 0.44705882, 0.24705882, 0.27265651, 0.720848  ,\n",
      "       0.15661784]), array([0., 1.])), (array([0.41568627, 0.36470588, 0.2627451 , 0.27055171, 0.78861789,\n",
      "       0.19576823]), array([1., 0.])), (array([0.26666667, 0.24705882, 0.20392157, 0.28690923, 0.78333112,\n",
      "       0.19228841]), array([1., 0.])), (array([0.36862745, 0.45490196, 0.32941176, 0.28731212, 0.74347745,\n",
      "       0.25917643]), array([0., 1.])), (array([0.29803922, 0.36078431, 0.28235294, 0.31640686, 0.81333754,\n",
      "       0.1848291 ]), array([1., 0.])), (array([0.17254902, 0.44705882, 0.21176471, 0.25547026, 0.78350558,\n",
      "       0.15300293]), array([0., 1.])), (array([0.12156863, 0.18039216, 0.18039216, 0.35524674, 0.76929723,\n",
      "       0.20578451]), array([1., 0.])), (array([0.25098039, 0.28627451, 0.23529412, 0.31445503, 0.79875008,\n",
      "       0.17910645]), array([1., 0.])), (array([0.31372549, 0.2627451 , 0.2627451 , 0.28409469, 0.76477051,\n",
      "       0.18013184]), array([1., 0.])), (array([0.39607843, 0.43921569, 0.28235294, 0.26087296, 0.78360495,\n",
      "       0.24980469]), array([0., 1.])), (array([0.09803922, 0.15294118, 0.15294118, 0.33424266, 0.75600518,\n",
      "       0.19199382]), array([1., 0.])), (array([0.24313725, 0.36862745, 0.19215686, 0.26459393, 0.72485713,\n",
      "       0.24029297]), array([0., 1.])), (array([0.42352941, 0.46666667, 0.44313725, 0.30203014, 0.81162739,\n",
      "       0.19150391]), array([1., 0.])), (array([0.11372549, 0.42352941, 0.17647059, 0.24755022, 0.74724906,\n",
      "       0.15949219]), array([0., 1.])), (array([0.35294118, 0.43921569, 0.45490196, 0.36165856, 0.76563801,\n",
      "       0.2094987 ]), array([1., 0.])), (array([0.3254902 , 0.35294118, 0.34117647, 0.30664372, 0.82331269,\n",
      "       0.19131836]), array([1., 0.])), (array([0.04313725, 0.26666667, 0.1254902 , 0.26008318, 0.7803914 ,\n",
      "       0.21755697]), array([0., 1.])), (array([0.16470588, 0.21176471, 0.17647059, 0.32517187, 0.80183052,\n",
      "       0.17438639]), array([1., 0.])), (array([0.14901961, 0.42745098, 0.2       , 0.25254462, 0.79174787,\n",
      "       0.16662272]), array([0., 1.])), (array([0.07058824, 0.32156863, 0.10196078, 0.2509404 , 0.822964  ,\n",
      "       0.19690592]), array([0., 1.])), (array([0.29803922, 0.25882353, 0.23921569, 0.25301608, 0.7707971 ,\n",
      "       0.18033691]), array([1., 0.])), (array([0.01960784, 0.25490196, 0.11372549, 0.26772849, 0.73206544,\n",
      "       0.22867513]), array([0., 1.])), (array([0.16470588, 0.43921569, 0.20392157, 0.25399459, 0.77889544,\n",
      "       0.15211914]), array([0., 1.])), (array([0.44313725, 0.34901961, 0.28235294, 0.27004079, 0.70529434,\n",
      "       0.18098307]), array([1., 0.])), (array([0.01960784, 0.24705882, 0.07843137, 0.2429469 , 0.74058242,\n",
      "       0.20894694]), array([0., 1.])), (array([0.12156863, 0.41960784, 0.2       , 0.27108543, 0.70389987,\n",
      "       0.1732666 ]), array([0., 1.])), (array([0.38431373, 0.36470588, 0.28627451, 0.31712742, 0.7858727 ,\n",
      "       0.22262044]), array([1., 0.])), (array([0.17254902, 0.24313725, 0.22352941, 0.3323605 , 0.74808294,\n",
      "       0.2007015 ]), array([1., 0.])), (array([0.12941176, 0.15686275, 0.15294118, 0.32133607, 0.80923362,\n",
      "       0.18458008]), array([1., 0.])), (array([0.10196078, 0.41568627, 0.16470588, 0.26022397, 0.72695826,\n",
      "       0.15973796]), array([0., 1.])), (array([0.16862745, 0.52941176, 0.25098039, 0.24091594, 0.78101462,\n",
      "       0.18361979]), array([0., 1.])), (array([0.10980392, 0.42352941, 0.17254902, 0.23882714, 0.7762205 ,\n",
      "       0.18875651]), array([0., 1.])), (array([0.29019608, 0.23529412, 0.18431373, 0.27632935, 0.80692329,\n",
      "       0.17380371]), array([1., 0.])), (array([0.26666667, 0.29411765, 0.2745098 , 0.3031623 , 0.77825388,\n",
      "       0.19688151]), array([1., 0.])), (array([0.11764706, 0.1254902 , 0.10980392, 0.3155041 , 0.79234074,\n",
      "       0.18430176]), array([1., 0.])), (array([0.16470588, 0.32156863, 0.15686275, 0.2435976 , 0.71011293,\n",
      "       0.22720378]), array([0., 1.])), (array([0.09411765, 0.10980392, 0.1254902 , 0.32473144, 0.81538427,\n",
      "       0.1772054 ]), array([1., 0.])), (array([0.08627451, 0.39215686, 0.16078431, 0.27057359, 0.70595036,\n",
      "       0.17293945]), array([0., 1.])), (array([0.2745098 , 0.27058824, 0.21568627, 0.29789377, 0.76441879,\n",
      "       0.19654297]), array([1., 0.])), (array([0.27058824, 0.29411765, 0.27058824, 0.32704719, 0.79785854,\n",
      "       0.18313477]), array([1., 0.])), (array([0.13333333, 0.48627451, 0.20784314, 0.23743335, 0.69071325,\n",
      "       0.19172689]), array([0., 1.])), (array([0.31372549, 0.27058824, 0.24313725, 0.25539622, 0.74892856,\n",
      "       0.17520345]), array([1., 0.])), (array([0.29019608, 0.36862745, 0.29803922, 0.32485402, 0.787373  ,\n",
      "       0.19778646]), array([1., 0.])), (array([0.07058824, 0.38039216, 0.14117647, 0.26130562, 0.81334262,\n",
      "       0.17104818]), array([0., 1.])), (array([0.43137255, 0.50588235, 0.53333333, 0.35706935, 0.71959137,\n",
      "       0.20510579]), array([1., 0.])), (array([0.25882353, 0.37254902, 0.19607843, 0.24537979, 0.7577035 ,\n",
      "       0.22584473]), array([0., 1.])), (array([0.33333333, 0.39215686, 0.30196078, 0.3236697 , 0.77503863,\n",
      "       0.18124349]), array([1., 0.])), (array([0.0627451 , 0.26666667, 0.1254902 , 0.26113547, 0.65238695,\n",
      "       0.21236979]), array([0., 1.])), (array([0.25882353, 0.28235294, 0.27058824, 0.30179249, 0.82360543,\n",
      "       0.18981934]), array([1., 0.])), (array([0.27058824, 0.33333333, 0.34901961, 0.35490676, 0.76092169,\n",
      "       0.20558757]), array([1., 0.])), (array([0.24705882, 0.28627451, 0.27843137, 0.3238972 , 0.76415485,\n",
      "       0.19238444]), array([1., 0.])), (array([0.16862745, 0.21176471, 0.18431373, 0.30840415, 0.7912366 ,\n",
      "       0.18166504]), array([1., 0.])), (array([0.21960784, 0.25490196, 0.25490196, 0.32229662, 0.81549326,\n",
      "       0.18513184]), array([1., 0.])), (array([0.02352941, 0.24313725, 0.10588235, 0.26416437, 0.74531725,\n",
      "       0.21028646]), array([0., 1.])), (array([0.37254902, 0.43921569, 0.25098039, 0.26458979, 0.70936115,\n",
      "       0.24352539]), array([0., 1.])), (array([0.06666667, 0.10980392, 0.12156863, 0.31756937, 0.80020609,\n",
      "       0.1870638 ]), array([1., 0.])), (array([0.05098039, 0.30980392, 0.12156863, 0.267479  , 0.81871996,\n",
      "       0.20237467]), array([0., 1.])), (array([0.2       , 0.25490196, 0.21176471, 0.32402454, 0.80727073,\n",
      "       0.18927897]), array([1., 0.])), (array([0.14117647, 0.30196078, 0.11764706, 0.2449756 , 0.77107594,\n",
      "       0.21069173]), array([0., 1.])), (array([0.39607843, 0.45490196, 0.29803922, 0.2594029 , 0.71889065,\n",
      "       0.23085938]), array([0., 1.])), (array([0.31764706, 0.36862745, 0.29411765, 0.30255627, 0.82248682,\n",
      "       0.17673828]), array([1., 0.])), (array([0.23137255, 0.26666667, 0.25098039, 0.30826634, 0.82370573,\n",
      "       0.19233073]), array([1., 0.])), (array([0.3372549 , 0.29019608, 0.25490196, 0.26540109, 0.72466674,\n",
      "       0.1723584 ]), array([1., 0.])), (array([0.06666667, 0.38039216, 0.11372549, 0.2502836 , 0.7917306 ,\n",
      "       0.16125326]), array([0., 1.])), (array([0.12156863, 0.4627451 , 0.19607843, 0.25341488, 0.70612772,\n",
      "       0.19314616]), array([0., 1.])), (array([0.4       , 0.36862745, 0.28235294, 0.31604645, 0.7570529 ,\n",
      "       0.2168099 ]), array([1., 0.])), (array([0.05882353, 0.2745098 , 0.17254902, 0.27384114, 0.74329687,\n",
      "       0.23228027]), array([0., 1.])), (array([0.1372549 , 0.15686275, 0.13333333, 0.32059561, 0.78896392,\n",
      "       0.17646647]), array([1., 0.])), (array([0.09411765, 0.38823529, 0.15294118, 0.24270902, 0.74645952,\n",
      "       0.19182454]), array([0., 1.])), (array([0.3254902 , 0.2745098 , 0.25098039, 0.26059201, 0.71945878,\n",
      "       0.17058105]), array([1., 0.])), (array([0.19607843, 0.24705882, 0.21176471, 0.30500587, 0.80397005,\n",
      "       0.18418294]), array([1., 0.])), (array([0.04705882, 0.30980392, 0.10588235, 0.25253342, 0.78390682,\n",
      "       0.19815592]), array([0., 1.])), (array([0.25882353, 0.27058824, 0.24705882, 0.29139367, 0.7257161 ,\n",
      "       0.19377116]), array([1., 0.])), (array([0.2745098 , 0.36862745, 0.21568627, 0.28375997, 0.63182301,\n",
      "       0.23240885]), array([0., 1.])), (array([0.28235294, 0.26666667, 0.24313725, 0.27732223, 0.73853603,\n",
      "       0.18297038]), array([1., 0.])), (array([0.19215686, 0.45882353, 0.23921569, 0.27120178, 0.70322609,\n",
      "       0.15709961]), array([0., 1.])), (array([0.24313725, 0.35686275, 0.16470588, 0.25462748, 0.71135311,\n",
      "       0.23124186]), array([0., 1.])), (array([0.2745098 , 0.25098039, 0.19215686, 0.27888079, 0.69410043,\n",
      "       0.18837077]), array([1., 0.])), (array([0.08235294, 0.39607843, 0.14901961, 0.255211  , 0.73015873,\n",
      "       0.16052083]), array([0., 1.])), (array([0.11372549, 0.42352941, 0.19215686, 0.26345409, 0.80874331,\n",
      "       0.19932943]), array([0., 1.])), (array([0.01960784, 0.24313725, 0.09019608, 0.24737144, 0.76705279,\n",
      "       0.21275228]), array([0., 1.])), (array([0.29411765, 0.28235294, 0.2627451 , 0.27933648, 0.75705029,\n",
      "       0.19014974]), array([1., 0.])), (array([0.03137255, 0.25882353, 0.08627451, 0.27315036, 0.75335246,\n",
      "       0.21588379]), array([0., 1.])), (array([0.08627451, 0.16078431, 0.17254902, 0.34650815, 0.79147941,\n",
      "       0.20924479]), array([1., 0.])), (array([0.0745098 , 0.38039216, 0.12941176, 0.25289903, 0.77904837,\n",
      "       0.15778646]), array([0., 1.])), (array([0.25490196, 0.2745098 , 0.25882353, 0.32513157, 0.79582383,\n",
      "       0.17896322]), array([1., 0.]))]\n"
     ]
    }
   ],
   "source": [
    "all_labels = [\"braunglas\", \"gruenglas\", \"weissglas\", \"keinglas\"]\n",
    "\n",
    "# Load the MNIST dataset\n",
    "dataframes = []\n",
    "\n",
    "# Loop through each CSV file in the directory\n",
    "for filename in os.listdir(\".\"):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Extract the label from the filename (e.g., label1.csv -> label1)\n",
    "        label = os.path.splitext(filename)[0]\n",
    "        \n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(filename, index_col=None)\n",
    "        \n",
    "        # Add a column for the label\n",
    "        df['label'] = label\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        dataframes.append(df)\n",
    "\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "\n",
    "combined_df = combined_df.sample(frac=1).reset_index(drop=False)\n",
    "\n",
    "# Example: Separate features and labels\n",
    "X = combined_df.drop(columns=['label', \"index\"]).values\n",
    "\n",
    "# y is 4 one-hot encoded columns for the 3 classes and 1 for the no class\n",
    "y = np.array([all_labels.index(v) for v in combined_df['label'].values])\n",
    "\n",
    "y = to_categorical(y, num_classes=2)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(list(zip(x_train, y_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(x_train.shape[1], activation='relu', input_shape=(x_train.shape[1],)))\n",
    "# model.add(Dense(1, activation='relu', input_shape=(1,)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"nadam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09019608 0.38431373 0.17647059 0.26757946 0.76535234 0.20844889] [0. 1.]\n",
      "[0.1372549  0.17647059 0.16078431 0.32431124 0.74807843 0.18628906] [1. 0.]\n",
      "[0.25490196 0.28235294 0.26666667 0.31435999 0.81633494 0.18057292] [1. 0.]\n",
      "[0.30980392 0.2627451  0.23921569 0.24941262 0.75845291 0.17911784] [1. 0.]\n",
      "[0.30588235 0.25098039 0.25098039 0.2832827  0.78475314 0.17674316] [1. 0.]\n",
      "[0.31764706 0.34509804 0.34509804 0.30665787 0.80667975 0.18063639] [1. 0.]\n",
      "[0.41960784 0.45490196 0.2745098  0.26152252 0.71580386 0.23274577] [0. 1.]\n",
      "[0.11764706 0.45882353 0.28627451 0.26596437 0.73852512 0.21783366] [0. 1.]\n",
      "[0.20784314 0.28627451 0.31372549 0.3482852  0.79757154 0.20687012] [1. 0.]\n",
      "[0.29019608 0.23137255 0.18823529 0.27455813 0.79593257 0.1768929 ] [1. 0.]\n",
      "[0.4        0.46666667 0.45882353 0.32201165 0.75368026 0.20090658] [1. 0.]\n",
      "[0.03137255 0.26666667 0.09803922 0.26503609 0.76568914 0.21554199] [0. 1.]\n",
      "[0.10980392 0.44705882 0.20784314 0.24620496 0.71310567 0.22509603] [0. 1.]\n",
      "[0.02745098 0.23529412 0.08627451 0.25619599 0.73854791 0.21882487] [0. 1.]\n",
      "[0.11372549 0.4        0.16862745 0.26784086 0.74937823 0.16575846] [0. 1.]\n",
      "[0.10980392 0.1254902  0.11372549 0.31880721 0.80884659 0.18467611] [1. 0.]\n",
      "[0.26666667 0.29411765 0.2745098  0.32672833 0.80047959 0.17984212] [1. 0.]\n",
      "[0.30196078 0.42352941 0.26666667 0.28843198 0.64245197 0.24296061] [0. 1.]\n",
      "[0.2745098  0.30588235 0.29019608 0.32144178 0.80572448 0.18308594] [1. 0.]\n",
      "[0.16078431 0.42745098 0.20392157 0.25735405 0.78869321 0.14534342] [0. 1.]\n",
      "[0.36862745 0.45490196 0.29019608 0.2672446  0.66326984 0.2427002 ] [0. 1.]\n",
      "[0.03529412 0.27058824 0.10196078 0.26216372 0.74466816 0.20720052] [0. 1.]\n",
      "[0.05882353 0.30196078 0.1254902  0.26662424 0.76648288 0.2002474 ] [0. 1.]\n",
      "[0.25490196 0.28235294 0.2627451  0.30898844 0.81013795 0.18505534] [1. 0.]\n",
      "[0.11372549 0.39215686 0.16470588 0.25290853 0.78513938 0.16035807] [0. 1.]\n",
      "[0.11372549 0.41176471 0.16470588 0.25155682 0.75953442 0.16207357] [0. 1.]\n",
      "[0.03137255 0.29019608 0.15294118 0.26712888 0.7351143  0.21878743] [0. 1.]\n",
      "[0.30588235 0.25882353 0.25098039 0.28634382 0.77435269 0.18010254] [1. 0.]\n",
      "[0.0745098  0.38039216 0.1254902  0.26512488 0.75409184 0.15747559] [0. 1.]\n",
      "[0.0627451  0.34509804 0.10980392 0.2503353  0.81494751 0.20214518] [0. 1.]\n",
      "[0.16078431 0.20784314 0.19607843 0.33456372 0.74593679 0.1905599 ] [1. 0.]\n",
      "[0.24313725 0.29019608 0.22745098 0.29845434 0.81445704 0.18923665] [1. 0.]\n",
      "[0.31764706 0.38823529 0.30980392 0.3046549  0.8026199  0.18548828] [1. 0.]\n",
      "[0.31764706 0.35686275 0.34509804 0.3204779  0.75817733 0.19512207] [1. 0.]\n",
      "[0.17254902 0.42745098 0.22352941 0.26247311 0.76067835 0.16243652] [0. 1.]\n",
      "[0.05098039 0.38431373 0.10588235 0.25225661 0.7877507  0.16774577] [0. 1.]\n",
      "[0.08627451 0.12941176 0.12941176 0.33119076 0.76480997 0.20330078] [1. 0.]\n",
      "[0.10588235 0.25882353 0.12941176 0.24980787 0.74117004 0.21189453] [0. 1.]\n",
      "[0.10588235 0.25882353 0.0745098  0.2450556  0.78650807 0.20642253] [0. 1.]\n",
      "[0.28627451 0.2627451  0.23137255 0.26603168 0.74145247 0.17690592] [1. 0.]\n",
      "[0.38039216 0.43921569 0.29019608 0.26791957 0.66322748 0.24168294] [0. 1.]\n",
      "[0.32941176 0.27843137 0.25882353 0.28086964 0.79847226 0.17523763] [1. 0.]\n",
      "[0.38431373 0.45882353 0.47843137 0.30573874 0.67255929 0.20651204] [1. 0.]\n",
      "[0.14901961 0.40784314 0.21176471 0.26131801 0.80145396 0.16436198] [0. 1.]\n",
      "[0.25490196 0.28627451 0.2745098  0.31316994 0.82009458 0.18911296] [1. 0.]\n",
      "[0.32156863 0.38039216 0.30196078 0.31911395 0.75615969 0.18022298] [1. 0.]\n",
      "[0.18431373 0.22352941 0.19215686 0.32668646 0.80463913 0.17367188] [1. 0.]\n",
      "[0.04705882 0.2627451  0.08627451 0.25009203 0.81030404 0.19624023] [0. 1.]\n",
      "[0.30588235 0.39607843 0.19607843 0.24171533 0.78577072 0.21366211] [0. 1.]\n",
      "[0.17254902 0.43921569 0.25098039 0.27585453 0.71378174 0.17914714] [0. 1.]\n",
      "[0.0745098  0.24705882 0.11764706 0.25628567 0.74302263 0.22194173] [0. 1.]\n",
      "[0.39215686 0.43529412 0.24313725 0.25358935 0.71196279 0.23495931] [0. 1.]\n",
      "[0.10980392 0.42352941 0.17254902 0.23922048 0.76952582 0.18906738] [0. 1.]\n",
      "[0.27058824 0.25490196 0.23921569 0.28218182 0.74504835 0.18471354] [1. 0.]\n",
      "[0.12156863 0.12941176 0.10980392 0.30707283 0.82485592 0.17937663] [1. 0.]\n",
      "[0.27058824 0.30196078 0.28627451 0.30847522 0.81511437 0.18322428] [1. 0.]\n",
      "[0.27843137 0.32941176 0.25882353 0.31430111 0.8132359  0.17750488] [1. 0.]\n",
      "[0.05490196 0.28627451 0.08627451 0.24685656 0.82772407 0.19510254] [0. 1.]\n",
      "[0.19607843 0.44705882 0.24705882 0.27265651 0.720848   0.15661784] [0. 1.]\n",
      "[0.41568627 0.36470588 0.2627451  0.27055171 0.78861789 0.19576823] [1. 0.]\n",
      "[0.26666667 0.24705882 0.20392157 0.28690923 0.78333112 0.19228841] [1. 0.]\n",
      "[0.36862745 0.45490196 0.32941176 0.28731212 0.74347745 0.25917643] [0. 1.]\n",
      "[0.29803922 0.36078431 0.28235294 0.31640686 0.81333754 0.1848291 ] [1. 0.]\n",
      "[0.17254902 0.44705882 0.21176471 0.25547026 0.78350558 0.15300293] [0. 1.]\n",
      "[0.12156863 0.18039216 0.18039216 0.35524674 0.76929723 0.20578451] [1. 0.]\n",
      "[0.25098039 0.28627451 0.23529412 0.31445503 0.79875008 0.17910645] [1. 0.]\n",
      "[0.31372549 0.2627451  0.2627451  0.28409469 0.76477051 0.18013184] [1. 0.]\n",
      "[0.39607843 0.43921569 0.28235294 0.26087296 0.78360495 0.24980469] [0. 1.]\n",
      "[0.09803922 0.15294118 0.15294118 0.33424266 0.75600518 0.19199382] [1. 0.]\n",
      "[0.24313725 0.36862745 0.19215686 0.26459393 0.72485713 0.24029297] [0. 1.]\n",
      "[0.42352941 0.46666667 0.44313725 0.30203014 0.81162739 0.19150391] [1. 0.]\n",
      "[0.11372549 0.42352941 0.17647059 0.24755022 0.74724906 0.15949219] [0. 1.]\n",
      "[0.35294118 0.43921569 0.45490196 0.36165856 0.76563801 0.2094987 ] [1. 0.]\n",
      "[0.3254902  0.35294118 0.34117647 0.30664372 0.82331269 0.19131836] [1. 0.]\n",
      "[0.04313725 0.26666667 0.1254902  0.26008318 0.7803914  0.21755697] [0. 1.]\n",
      "[0.16470588 0.21176471 0.17647059 0.32517187 0.80183052 0.17438639] [1. 0.]\n",
      "[0.14901961 0.42745098 0.2        0.25254462 0.79174787 0.16662272] [0. 1.]\n",
      "[0.07058824 0.32156863 0.10196078 0.2509404  0.822964   0.19690592] [0. 1.]\n",
      "[0.29803922 0.25882353 0.23921569 0.25301608 0.7707971  0.18033691] [1. 0.]\n",
      "[0.01960784 0.25490196 0.11372549 0.26772849 0.73206544 0.22867513] [0. 1.]\n",
      "[0.16470588 0.43921569 0.20392157 0.25399459 0.77889544 0.15211914] [0. 1.]\n",
      "[0.44313725 0.34901961 0.28235294 0.27004079 0.70529434 0.18098307] [1. 0.]\n",
      "[0.01960784 0.24705882 0.07843137 0.2429469  0.74058242 0.20894694] [0. 1.]\n",
      "[0.12156863 0.41960784 0.2        0.27108543 0.70389987 0.1732666 ] [0. 1.]\n",
      "[0.38431373 0.36470588 0.28627451 0.31712742 0.7858727  0.22262044] [1. 0.]\n",
      "[0.17254902 0.24313725 0.22352941 0.3323605  0.74808294 0.2007015 ] [1. 0.]\n",
      "[0.12941176 0.15686275 0.15294118 0.32133607 0.80923362 0.18458008] [1. 0.]\n",
      "[0.10196078 0.41568627 0.16470588 0.26022397 0.72695826 0.15973796] [0. 1.]\n",
      "[0.16862745 0.52941176 0.25098039 0.24091594 0.78101462 0.18361979] [0. 1.]\n",
      "[0.10980392 0.42352941 0.17254902 0.23882714 0.7762205  0.18875651] [0. 1.]\n",
      "[0.29019608 0.23529412 0.18431373 0.27632935 0.80692329 0.17380371] [1. 0.]\n",
      "[0.26666667 0.29411765 0.2745098  0.3031623  0.77825388 0.19688151] [1. 0.]\n",
      "[0.11764706 0.1254902  0.10980392 0.3155041  0.79234074 0.18430176] [1. 0.]\n",
      "[0.16470588 0.32156863 0.15686275 0.2435976  0.71011293 0.22720378] [0. 1.]\n",
      "[0.09411765 0.10980392 0.1254902  0.32473144 0.81538427 0.1772054 ] [1. 0.]\n",
      "[0.08627451 0.39215686 0.16078431 0.27057359 0.70595036 0.17293945] [0. 1.]\n",
      "[0.2745098  0.27058824 0.21568627 0.29789377 0.76441879 0.19654297] [1. 0.]\n",
      "[0.27058824 0.29411765 0.27058824 0.32704719 0.79785854 0.18313477] [1. 0.]\n",
      "[0.13333333 0.48627451 0.20784314 0.23743335 0.69071325 0.19172689] [0. 1.]\n",
      "[0.31372549 0.27058824 0.24313725 0.25539622 0.74892856 0.17520345] [1. 0.]\n",
      "[0.29019608 0.36862745 0.29803922 0.32485402 0.787373   0.19778646] [1. 0.]\n",
      "[0.07058824 0.38039216 0.14117647 0.26130562 0.81334262 0.17104818] [0. 1.]\n",
      "[0.43137255 0.50588235 0.53333333 0.35706935 0.71959137 0.20510579] [1. 0.]\n",
      "[0.25882353 0.37254902 0.19607843 0.24537979 0.7577035  0.22584473] [0. 1.]\n",
      "[0.33333333 0.39215686 0.30196078 0.3236697  0.77503863 0.18124349] [1. 0.]\n",
      "[0.0627451  0.26666667 0.1254902  0.26113547 0.65238695 0.21236979] [0. 1.]\n",
      "[0.25882353 0.28235294 0.27058824 0.30179249 0.82360543 0.18981934] [1. 0.]\n",
      "[0.27058824 0.33333333 0.34901961 0.35490676 0.76092169 0.20558757] [1. 0.]\n",
      "[0.24705882 0.28627451 0.27843137 0.3238972  0.76415485 0.19238444] [1. 0.]\n",
      "[0.16862745 0.21176471 0.18431373 0.30840415 0.7912366  0.18166504] [1. 0.]\n",
      "[0.21960784 0.25490196 0.25490196 0.32229662 0.81549326 0.18513184] [1. 0.]\n",
      "[0.02352941 0.24313725 0.10588235 0.26416437 0.74531725 0.21028646] [0. 1.]\n",
      "[0.37254902 0.43921569 0.25098039 0.26458979 0.70936115 0.24352539] [0. 1.]\n",
      "[0.06666667 0.10980392 0.12156863 0.31756937 0.80020609 0.1870638 ] [1. 0.]\n",
      "[0.05098039 0.30980392 0.12156863 0.267479   0.81871996 0.20237467] [0. 1.]\n",
      "[0.2        0.25490196 0.21176471 0.32402454 0.80727073 0.18927897] [1. 0.]\n",
      "[0.14117647 0.30196078 0.11764706 0.2449756  0.77107594 0.21069173] [0. 1.]\n",
      "[0.39607843 0.45490196 0.29803922 0.2594029  0.71889065 0.23085938] [0. 1.]\n",
      "[0.31764706 0.36862745 0.29411765 0.30255627 0.82248682 0.17673828] [1. 0.]\n",
      "[0.23137255 0.26666667 0.25098039 0.30826634 0.82370573 0.19233073] [1. 0.]\n",
      "[0.3372549  0.29019608 0.25490196 0.26540109 0.72466674 0.1723584 ] [1. 0.]\n",
      "[0.06666667 0.38039216 0.11372549 0.2502836  0.7917306  0.16125326] [0. 1.]\n",
      "[0.12156863 0.4627451  0.19607843 0.25341488 0.70612772 0.19314616] [0. 1.]\n",
      "[0.4        0.36862745 0.28235294 0.31604645 0.7570529  0.2168099 ] [1. 0.]\n",
      "[0.05882353 0.2745098  0.17254902 0.27384114 0.74329687 0.23228027] [0. 1.]\n",
      "[0.1372549  0.15686275 0.13333333 0.32059561 0.78896392 0.17646647] [1. 0.]\n",
      "[0.09411765 0.38823529 0.15294118 0.24270902 0.74645952 0.19182454] [0. 1.]\n",
      "[0.3254902  0.2745098  0.25098039 0.26059201 0.71945878 0.17058105] [1. 0.]\n",
      "[0.19607843 0.24705882 0.21176471 0.30500587 0.80397005 0.18418294] [1. 0.]\n",
      "[0.04705882 0.30980392 0.10588235 0.25253342 0.78390682 0.19815592] [0. 1.]\n",
      "[0.25882353 0.27058824 0.24705882 0.29139367 0.7257161  0.19377116] [1. 0.]\n",
      "[0.2745098  0.36862745 0.21568627 0.28375997 0.63182301 0.23240885] [0. 1.]\n",
      "[0.28235294 0.26666667 0.24313725 0.27732223 0.73853603 0.18297038] [1. 0.]\n",
      "[0.19215686 0.45882353 0.23921569 0.27120178 0.70322609 0.15709961] [0. 1.]\n",
      "[0.24313725 0.35686275 0.16470588 0.25462748 0.71135311 0.23124186] [0. 1.]\n",
      "[0.2745098  0.25098039 0.19215686 0.27888079 0.69410043 0.18837077] [1. 0.]\n",
      "[0.08235294 0.39607843 0.14901961 0.255211   0.73015873 0.16052083] [0. 1.]\n",
      "[0.11372549 0.42352941 0.19215686 0.26345409 0.80874331 0.19932943] [0. 1.]\n",
      "[0.01960784 0.24313725 0.09019608 0.24737144 0.76705279 0.21275228] [0. 1.]\n",
      "[0.29411765 0.28235294 0.2627451  0.27933648 0.75705029 0.19014974] [1. 0.]\n",
      "[0.03137255 0.25882353 0.08627451 0.27315036 0.75335246 0.21588379] [0. 1.]\n",
      "[0.08627451 0.16078431 0.17254902 0.34650815 0.79147941 0.20924479] [1. 0.]\n",
      "[0.0745098  0.38039216 0.12941176 0.25289903 0.77904837 0.15778646] [0. 1.]\n",
      "[0.25490196 0.2745098  0.25882353 0.32513157 0.79582383 0.17896322] [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(x_train)):\n",
    "    print(x_train[i], y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4929 - loss: 0.6975\n",
      "Epoch 2/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5502 - loss: 0.6901 \n",
      "Epoch 3/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5255 - loss: 0.6914 \n",
      "Epoch 4/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4734 - loss: 0.6968 \n",
      "Epoch 5/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5185 - loss: 0.6906 \n",
      "Epoch 6/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4860 - loss: 0.6941 \n",
      "Epoch 7/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5420 - loss: 0.6867 \n",
      "Epoch 8/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5090 - loss: 0.6903 \n",
      "Epoch 9/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5177 - loss: 0.6886  \n",
      "Epoch 10/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4873 - loss: 0.6919 \n",
      "Epoch 11/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5680 - loss: 0.6827 \n",
      "Epoch 12/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5094 - loss: 0.6874 \n",
      "Epoch 13/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5055 - loss: 0.6883 \n",
      "Epoch 14/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5359 - loss: 0.6845 \n",
      "Epoch 15/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5181 - loss: 0.6856 \n",
      "Epoch 16/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5124 - loss: 0.6859  \n",
      "Epoch 17/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4795 - loss: 0.6892 \n",
      "Epoch 18/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5276 - loss: 0.6835 \n",
      "Epoch 19/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4955 - loss: 0.6858  \n",
      "Epoch 20/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5051 - loss: 0.6846 \n",
      "Epoch 21/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5003 - loss: 0.6821 \n",
      "Epoch 22/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5450 - loss: 0.6783 \n",
      "Epoch 23/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5012 - loss: 0.6820 \n",
      "Epoch 24/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5398 - loss: 0.6787 \n",
      "Epoch 25/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5353 - loss: 0.6770 \n",
      "Epoch 26/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5074 - loss: 0.6766 \n",
      "Epoch 27/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5172 - loss: 0.6757  \n",
      "Epoch 28/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5596 - loss: 0.6743 \n",
      "Epoch 29/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5502 - loss: 0.6683  \n",
      "Epoch 30/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5736 - loss: 0.6663 \n",
      "Epoch 31/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5344 - loss: 0.6702 \n",
      "Epoch 32/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5911 - loss: 0.6658 \n",
      "Epoch 33/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5823 - loss: 0.6652 \n",
      "Epoch 34/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6166 - loss: 0.6602 \n",
      "Epoch 35/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6123 - loss: 0.6588 \n",
      "Epoch 36/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6324 - loss: 0.6559  \n",
      "Epoch 37/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6496 - loss: 0.6551 \n",
      "Epoch 38/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7289 - loss: 0.6430 \n",
      "Epoch 39/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7189 - loss: 0.6527 \n",
      "Epoch 40/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7795 - loss: 0.6383 \n",
      "Epoch 41/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7397 - loss: 0.6450  \n",
      "Epoch 42/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7758 - loss: 0.6340 \n",
      "Epoch 43/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7501 - loss: 0.6390 \n",
      "Epoch 44/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8095 - loss: 0.6296 \n",
      "Epoch 45/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7786 - loss: 0.6299 \n",
      "Epoch 46/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7812 - loss: 0.6279 \n",
      "Epoch 47/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7448 - loss: 0.6285 \n",
      "Epoch 48/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7713 - loss: 0.6227 \n",
      "Epoch 49/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7740 - loss: 0.6186 \n",
      "Epoch 50/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7917 - loss: 0.6134 \n",
      "Epoch 51/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8006 - loss: 0.6026 \n",
      "Epoch 52/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8142 - loss: 0.5998 \n",
      "Epoch 53/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7976 - loss: 0.5903 \n",
      "Epoch 54/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7273 - loss: 0.6029 \n",
      "Epoch 55/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7925 - loss: 0.5888 \n",
      "Epoch 56/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7993 - loss: 0.5886  \n",
      "Epoch 57/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8135 - loss: 0.5838\n",
      "Epoch 58/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8293 - loss: 0.5797 \n",
      "Epoch 59/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7866 - loss: 0.5807 \n",
      "Epoch 60/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7907 - loss: 0.5725 \n",
      "Epoch 61/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7912 - loss: 0.5686  \n",
      "Epoch 62/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7995 - loss: 0.5619 \n",
      "Epoch 63/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8427 - loss: 0.5616 \n",
      "Epoch 64/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8452 - loss: 0.5563 \n",
      "Epoch 65/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8682 - loss: 0.5460 \n",
      "Epoch 66/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8588 - loss: 0.5424  \n",
      "Epoch 67/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8796 - loss: 0.5385 \n",
      "Epoch 68/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9180 - loss: 0.5257 \n",
      "Epoch 69/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8721 - loss: 0.5241 \n",
      "Epoch 70/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8772 - loss: 0.5235 \n",
      "Epoch 71/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8614 - loss: 0.5116 \n",
      "Epoch 72/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9097 - loss: 0.5076 \n",
      "Epoch 73/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9290 - loss: 0.5024 \n",
      "Epoch 74/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9544 - loss: 0.4922  \n",
      "Epoch 75/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9391 - loss: 0.4936 \n",
      "Epoch 76/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9550 - loss: 0.4899  \n",
      "Epoch 77/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.4722 \n",
      "Epoch 78/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9489 - loss: 0.4803 \n",
      "Epoch 79/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9648 - loss: 0.4640 \n",
      "Epoch 80/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9728 - loss: 0.4590 \n",
      "Epoch 81/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9716 - loss: 0.4507 \n",
      "Epoch 82/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9870 - loss: 0.4457 \n",
      "Epoch 83/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9753 - loss: 0.4378 \n",
      "Epoch 84/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9578 - loss: 0.4291 \n",
      "Epoch 85/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9708 - loss: 0.4222 \n",
      "Epoch 86/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9664 - loss: 0.4287 \n",
      "Epoch 87/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9673 - loss: 0.4205 \n",
      "Epoch 88/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9683 - loss: 0.4053 \n",
      "Epoch 89/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9832 - loss: 0.3977 \n",
      "Epoch 90/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.4008  \n",
      "Epoch 91/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.3934 \n",
      "Epoch 92/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.3780 \n",
      "Epoch 93/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.3731  \n",
      "Epoch 94/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.3770 \n",
      "Epoch 95/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.3574 \n",
      "Epoch 96/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.3589 \n",
      "Epoch 97/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.3478  \n",
      "Epoch 98/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.3348 \n",
      "Epoch 99/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.3282 \n",
      "Epoch 100/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9928 - loss: 0.3187 \n",
      "Epoch 101/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.3114 \n",
      "Epoch 102/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.3237 \n",
      "Epoch 103/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.3087 \n",
      "Epoch 104/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.3074 \n",
      "Epoch 105/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9928 - loss: 0.2895 \n",
      "Epoch 106/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9831 - loss: 0.2860 \n",
      "Epoch 107/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9813 - loss: 0.2834  \n",
      "Epoch 108/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9818 - loss: 0.2887 \n",
      "Epoch 109/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.2692 \n",
      "Epoch 110/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.2765 \n",
      "Epoch 111/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9946 - loss: 0.2599 \n",
      "Epoch 112/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.2649 \n",
      "Epoch 113/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.2558 \n",
      "Epoch 114/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9868 - loss: 0.2588\n",
      "Epoch 115/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.2374  \n",
      "Epoch 116/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9946 - loss: 0.2407 \n",
      "Epoch 117/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.2328 \n",
      "Epoch 118/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.2283  \n",
      "Epoch 119/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9977 - loss: 0.2266 \n",
      "Epoch 120/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.2236 \n",
      "Epoch 121/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.2176 \n",
      "Epoch 122/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.2081 \n",
      "Epoch 123/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.2066 \n",
      "Epoch 124/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.2077 \n",
      "Epoch 125/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.1932 \n",
      "Epoch 126/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9832 - loss: 0.2010 \n",
      "Epoch 127/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9832 - loss: 0.1952 \n",
      "Epoch 128/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.1861 \n",
      "Epoch 129/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.1892 \n",
      "Epoch 130/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.1765 \n",
      "Epoch 131/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.1740 \n",
      "Epoch 132/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.1796 \n",
      "Epoch 133/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.1674 \n",
      "Epoch 134/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.1750 \n",
      "Epoch 135/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.1664 \n",
      "Epoch 136/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.1595 \n",
      "Epoch 137/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.1684 \n",
      "Epoch 138/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.1632  \n",
      "Epoch 139/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.1575 \n",
      "Epoch 140/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.1461 \n",
      "Epoch 141/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.1490 \n",
      "Epoch 142/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.1487 \n",
      "Epoch 143/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.1359 \n",
      "Epoch 144/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.1308 \n",
      "Epoch 145/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9946 - loss: 0.1383 \n",
      "Epoch 146/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.1403 \n",
      "Epoch 147/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.1394 \n",
      "Epoch 148/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.1269 \n",
      "Epoch 149/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.1287 \n",
      "Epoch 150/150\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.1233  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1153  \n",
      "Test accuracy: 1.0000 and loss: 0.1157\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=150, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {test_accuracy:.4f} and loss: {test_loss:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
